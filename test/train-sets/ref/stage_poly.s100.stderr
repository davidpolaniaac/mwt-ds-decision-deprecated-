Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = train-sets/rcv1_small.dat
num sources = 1
average    since         example     example  current  current  current
loss       last          counter      weight    label  predict features
1.000000   1.000000            1         1.0   1.0000   0.0000       50
1.159804   1.319608            2         2.0  -1.0000   0.1487      103
1.036629   0.913455            4         4.0  -1.0000  -0.0996      134
0.913158   0.789687            8         8.0  -1.0000  -0.3868      145
0.853525   0.793891           16        16.0   1.0000   0.0040       23
0.857877   0.862230           32        32.0  -1.0000  -0.1942       31
0.866947   0.876017           64        64.0  -1.0000  -0.6024       60
0.845120   0.823293          128       128.0   1.0000   0.4470      105
0.689798   0.534476          256       256.0   1.0000   0.3825      122
0.586888   0.483978          512       512.0  -1.0000   0.1124       74
0.492272   0.397656         1024      1024.0  -1.0000  -0.4748       99
0.398926   0.305580         2048      2048.0   1.0000   0.2225      121
0.348324   0.297722         4096      4096.0  -1.0000   0.3343      566
0.307173   0.266022         8192      8192.0  -1.0000  -0.4686     1844

finished run
number of examples per pass = 10000
passes used = 1
weighted example sum = 10000
weighted label sum = -636
average loss = 0.295676
best constant = -0.0636
total feature number = 7648795
