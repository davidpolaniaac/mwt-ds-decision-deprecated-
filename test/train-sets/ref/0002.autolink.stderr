Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
predictions = 0002.autolink.predict
using no cache
Reading datafile = train-sets/0002.dat
num sources = 1
average    since         example     example  current  current  current
loss       last          counter      weight    label  predict features
0.271591   0.271591            1         1.0   0.5211   0.0000       15
0.136121   0.000650            2         2.0   0.5353   0.5098       15
0.150865   0.165610            4         4.0   0.5854   0.9858       15
0.118837   0.086808            8         8.0   0.5575   0.4187       15
0.101632   0.084426           16        16.0   0.5878   0.3575       15
0.055032   0.008432           32        32.0   0.6038   0.6153       15
0.033363   0.011695           64        64.0   0.5683   0.4726       15
0.019559   0.005755          128       128.0   0.5351   0.5156       15
0.011373   0.003187          256       256.0   0.5385   0.5619       15
0.006824   0.002274          512       512.0   0.5053   0.5032       15
0.003776   0.000729         1024      1024.0   0.5750   0.5977       15
0.002082   0.000388         2048      2048.0   0.5204   0.5008       15
0.001143   0.000204         4096      4096.0   0.5042   0.4979       15
0.000757   0.000370         8192      8192.0   0.4967   0.5100       15
0.000526   0.000296        16384     16384.0   0.5011   0.5125       15
0.000418   0.000309        32768     32768.0   0.3915   0.3944       15
0.000452   0.000485        65536     65536.0   0.5043   0.4944       15

finished run
number of examples per pass = 74746
passes used = 1
weighted example sum = 69521
weighted label sum = 35113.3
average loss = 0.000455838
best constant = 0.505074
best constant's loss = 0.249974
total feature number = 1119986
