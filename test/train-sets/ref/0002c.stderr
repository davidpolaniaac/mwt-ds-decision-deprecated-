Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.45
final_regressor = models/0002c.model
using no cache
Reading datafile = train-sets/0002.dat
num sources = 1
average    since         example     example  current  current  current
loss       last          counter      weight    label  predict features
0.271591   0.271591            1         1.0   0.5211   0.0000       15
0.136335   0.001079            2         2.0   0.5353   0.5024       15
0.127714   0.119093            4         4.0   0.5854   0.8683       15
0.107065   0.086416            8         8.0   0.5575   0.4216       15
0.095150   0.083235           16        16.0   0.5878   0.3525       15
0.051881   0.008611           32        32.0   0.6038   0.6129       15
0.032536   0.013191           64        64.0   0.5683   0.4646       15
0.019171   0.005807          128       128.0   0.5351   0.5008       15
0.011247   0.003322          256       256.0   0.5385   0.5604       15
0.006696   0.002146          512       512.0   0.5053   0.5142       15
0.003660   0.000625         1024      1024.0   0.5750   0.6010       15
0.002012   0.000364         2048      2048.0   0.5204   0.4991       15
0.001098   0.000185         4096      4096.0   0.5042   0.4956       15
0.000728   0.000358         8192      8192.0   0.4967   0.5118       15
0.000521   0.000313        16384     16384.0   0.5011   0.5153       15
0.000419   0.000318        32768     32768.0   0.3915   0.3971       15
0.000481   0.000543        65536     65536.0   0.5043   0.4943       15

finished run
number of examples per pass = 74746
passes used = 1
weighted example sum = 69521
weighted label sum = 35113.3
average loss = 0.000487239
best constant = 0.505074
best constant's loss = 0.249974
total feature number = 1119986
