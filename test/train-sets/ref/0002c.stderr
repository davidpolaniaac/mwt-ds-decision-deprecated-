final_regressor = models/0002c.model
Num weight bits = 18
learning rate = 4
initial_t = 1
power_t = 0.45
using no cache
Reading from train-sets/0002.dat
num sources = 1
average    since         example     example  current  current  current
loss       last          counter      weight    label  predict features
0.109628   0.109628            3         3.0   0.5498   0.3560       15
0.072405   0.035182            6         6.0   0.2681   0.0000       15
0.063346   0.052476           11        11.0   0.4315   0.0000       15
0.043027   0.022708           22        22.0   0.5519   0.5441       15
0.023864   0.004700           44        44.0   0.5514   0.6156       15
0.014750   0.005425           87        87.0   0.5140   0.5079       15
0.009588   0.004426          174       174.0   0.5596   0.5433       15
0.006579   0.003571          348       348.0   0.5475   0.5502       15
0.004093   0.001607          696       696.0   0.3421   0.3397       15
0.002491   0.000888         1392      1392.0   0.4996   0.5167       15
0.001464   0.000437         2784      2784.0   0.5090   0.5186       15
0.000916   0.000368         5568      5568.0   0.6413   0.6401       15
0.000672   0.000428        11135     11135.0   0.3869   0.4281       15
0.000496   0.000320        22269     22269.0   0.5063   0.5078       15
0.000478   0.000460        44537     44537.0   0.4905   0.4793       15

finished run
number of examples = 74746
weighted example sum = 6.952e+04
weighted label sum = 3.511e+04
average loss = 0.000529
best constant = 0.5051
best constant's loss = 0.25
total feature number = 1121190
