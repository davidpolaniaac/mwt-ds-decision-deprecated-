Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.45
final_regressor = models/0002c.model
using no cache
Reading datafile = train-sets/0002.dat
num sources = 1
average    since         example     example  current  current  current
loss       last          counter      weight    label  predict features
0.271591   0.271591            1         1.0   0.5211   0.0000       15
0.224821   0.178050            2         2.0   0.5353   0.1133       15
0.172237   0.119654            4         4.0   0.5854   0.2845       15
0.147987   0.123737            8         8.0   0.5575   0.2198       15
0.126423   0.104859           16        16.0   0.5878   0.2807       15
0.078709   0.030995           32        32.0   0.6038   0.5387       15
0.058175   0.037641           64        64.0   0.5683   0.3630       15
0.042723   0.027271          128       128.0   0.5351   0.3959       15
0.026552   0.010380          256       256.0   0.5385   0.5438       15
0.014833   0.003115          512       512.0   0.5053   0.5114       15
0.008091   0.001348         1024      1024.0   0.5750   0.5943       15
0.004439   0.000787         2048      2048.0   0.5204   0.4895       15
0.002384   0.000328         4096      4096.0   0.5042   0.4919       15
0.001481   0.000579         8192      8192.0   0.4967   0.5380       15
0.000963   0.000445        16384     16384.0   0.5011   0.5018       15
0.000759   0.000555        32768     32768.0   0.3915   0.4083       15
0.000870   0.000981        65536     65536.0   0.5043   0.4832       15

finished run
number of examples per pass = 74746
passes used = 1
weighted example sum = 69521
weighted label sum = 35113.3
average loss = 0.000871885
best constant = 0.505074
best constant's loss = 0.249974
total feature number = 1119986
