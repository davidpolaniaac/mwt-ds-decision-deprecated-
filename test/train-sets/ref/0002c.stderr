creating quadratic features for pairs: ff 
final_regressor = models/0002c.model
Num weight bits = 18
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading from train-sets/0002.dat
num sources = 1
average    since         example     example  current  current  current
loss       last          counter      weight    label  predict features
0.129897   0.129897            3         3.0   0.5498   0.2446      184
0.094762   0.059628            6         6.0   0.2681   0.3174      184
0.058652   0.015319           11        11.0   0.4315   0.3735      184
0.056710   0.054768           22        22.0   0.5519   0.5638      184
0.031432   0.006153           44        44.0   0.5514   0.6265      184
0.023202   0.014781           87        87.0   0.5140   0.5131      184
0.016406   0.009610          174       174.0   0.5596   0.5151      184
0.011554   0.006701          348       348.0   0.5475   0.5345      184
0.007422   0.003290          696       696.0   0.3421   0.4426      184
0.004544   0.001666         1392      1392.0   0.4996   0.5301      184
0.002645   0.000745         2784      2784.0   0.5090   0.5307      184
0.001552   0.000459         5568      5568.0   0.6413   0.6150      184
0.001110   0.000669        11135     11135.0   0.3869   0.4308      184
0.000834   0.000558        22269     22269.0   0.5063   0.5028      184
0.000812   0.000791        44537     44537.0   0.4905   0.4591      184

finished run
number of examples = 74746
weighted example sum = 6.952e+04
weighted label sum = 3.511e+04
average loss = 0.0007851
best constant = 0.5051
best constant's loss = 0.25
total feature number = 13753264
