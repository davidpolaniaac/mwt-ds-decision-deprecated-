final_regressor = models/0002c.model
Num weight bits = 18
learning rate = 10
initial_t = 1
power_t = 0.45
using no cache
Reading from train-sets/0002.dat
num sources = 1
average    since         example     example  current  current  current
loss       last          counter      weight    label  predict features
0.110761   0.110761            3         3.0   0.5498   0.3554       15
0.070749   0.030737            6         6.0   0.2681   0.0000       15
0.064487   0.056973           11        11.0   0.4315   0.0000       15
0.040053   0.015618           22        22.0   0.5519   0.5528       15
0.021985   0.003917           44        44.0   0.5514   0.6252       15
0.014055   0.005941           87        87.0   0.5140   0.5149       15
0.009634   0.005212          174       174.0   0.5596   0.5423       15
0.006675   0.003717          348       348.0   0.5475   0.5561       15
0.004216   0.001756          696       696.0   0.3421   0.3817       15
0.002563   0.000911         1392      1392.0   0.4996   0.5136       15
0.001511   0.000458         2784      2784.0   0.5090   0.5155       15
0.000935   0.000359         5568      5568.0   0.6413   0.6326       15
0.000717   0.000500        11135     11135.0   0.3869   0.4205       15
0.000532   0.000347        22269     22269.0   0.5063   0.5103       15
0.000528   0.000524        44537     44537.0   0.4905   0.4844       15

finished run
number of examples = 74746
weighted example sum = 6.952e+04
weighted label sum = 3.511e+04
average loss = 0.000527
best constant = 0.5051
best constant's loss = 0.25
total feature number = 1121190
