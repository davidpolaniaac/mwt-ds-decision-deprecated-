using l1 regularization = 0.01
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
final_regressor = models/mask.model
using no cache
Reading datafile = train-sets/0001.dat
num sources = 1
average    since         example     example  current  current  current
loss       last          counter      weight    label  predict features
1.000000   1.000000            1         1.0   1.0000   0.0000       51
0.508353   0.016707            2         2.0   0.0000   0.1293      104
0.260650   0.012946            4         4.0   0.0000   0.0607      135
0.242874   0.225099            8         8.0   0.0000   0.2086      146
0.250588   0.258302           16        16.0   1.0000   0.3075       24
0.237444   0.224299           32        32.0   0.0000   0.2321       32
0.233955   0.230466           64        64.0   0.0000   0.2063       61
0.221396   0.208837          128       128.0   1.0000   0.7676      106

finished run
number of examples per pass = 200
passes used = 1
weighted example sum = 200
weighted label sum = 91
average loss = 0.19509
best constant = 0.455
best constant's loss = 0.247975
total feature number = 15482
