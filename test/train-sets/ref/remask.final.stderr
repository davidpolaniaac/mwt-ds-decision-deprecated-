Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = train-sets/0001.dat
num sources = 1
average    since         example     example  current  current  current
loss       last          counter      weight    label  predict features
0.021895   0.021895            1         1.0   1.0000   0.8520       51
0.043325   0.064754            2         2.0   0.0000   0.2545      104
0.036796   0.030268            4         4.0   0.0000   0.1664      135
0.029048   0.021300            8         8.0   0.0000   0.0626      146
0.023810   0.018571           16        16.0   1.0000   0.8677       24
0.017809   0.011808           32        32.0   0.0000   0.0709       32
0.016337   0.014865           64        64.0   0.0000   0.0510       61
0.014818   0.013299          128       128.0   1.0000   0.8484      106

finished run
number of examples per pass = 200
passes used = 1
weighted example sum = 200
weighted label sum = 91
average loss = 0.0133871
best constant = 0.455
best constant's loss = 0.247975
total feature number = 15482
