final_regressor = models/0021.model
Num weight bits = 16
learning rate = 10
initial_t = 1
power_t = 0.5
decay_learning_rate = 1
randomly initializing neural network output weights and hidden bias
creating cache_file = train-sets/3parity.cache
Reading from train-sets/3parity
num sources = 1
average    since         example     example  current  current  current
loss       last          counter      weight    label  predict features
1.550870   1.550870            3         3.0   1.0000  -1.0000        4
1.919601   2.288332            6         6.0   1.0000   0.7762        4
2.011136   2.120978           11        11.0   1.0000  -1.0000        4
2.154879   2.298622           22        22.0   1.0000   0.3713        4
2.354257   2.553634           44        44.0  -1.0000   1.0000        4
2.286332   2.216828           87        87.0  -1.0000   1.0000        4
2.222494   2.158656          174       174.0   1.0000   0.8935        4
1.716411   1.210328          348       348.0  -1.0000  -0.9598        4
1.368979   1.021548          696       696.0   1.0000   0.9726        4
1.151750   0.934520         1392      1392.0   1.0000   0.9991        4
0.979195   0.806641         2784      2784.0   1.0000   0.9794        4
0.748329   0.517463         5568      5568.0   1.0000   1.0000        4
0.374198   0.000000        11135     11135.0  -1.0000  -1.0000        4

finished run
number of examples = 16000
weighted example sum = 1.6e+04
weighted label sum = 0
average loss = 0.2604
best constant = -6.25e-05
total feature number = 64000
