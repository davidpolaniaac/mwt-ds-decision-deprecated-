final_regressor = models/0021.model
Num weight bits = 16
learning rate = 10
initial_t = 1
power_t = 0.5
decay_learning_rate = 1
creating cache_file = train-sets/3parity.cache
Reading datafile = train-sets/3parity
num sources = 1
average    since         example     example  current  current  current
loss       last          counter      weight    label  predict features
0.847482   0.847482            1         1.0  -1.0000  -0.0794        4
0.423741   0.000000            2         2.0  -1.0000  -1.0000        4
2.009758   3.595775            4         4.0  -1.0000   0.7865        4
2.277648   2.545539            8         8.0   1.0000  -0.4412        4
2.580568   2.883487           16        16.0   1.0000  -0.9064        4
2.774777   2.968986           32        32.0   1.0000  -1.0000        4
2.848554   2.922331           64        64.0   1.0000  -0.9219        4
2.852599   2.856644          128       128.0   1.0000  -0.8698        4
2.659174   2.465749          256       256.0   1.0000  -0.8879        4
1.913132   1.167089          512       512.0   1.0000   1.0000        4
1.462811   1.012491         1024      1024.0   1.0000   0.9207        4
1.147027   0.831242         2048      2048.0   1.0000   0.8893        4
0.963513   0.779999         4096      4096.0   1.0000   1.0000        4
0.526985   0.090457         8192      8192.0   1.0000   1.0000        4
0.263493   0.000000        16384     16384.0   1.0000   1.0000        4

finished run
number of examples per pass = 8
passes used = 3000
weighted example sum = 24000
weighted label sum = 0
average loss = 0.179878
best constant = -4.16684e-05
total feature number = 96000
