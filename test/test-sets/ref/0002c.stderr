using no cache
Reading from train-sets/0002.dat
num sources = 1
Num weight bits = 18
learning rate = 10
initial_t = 1
power_t = 0.5
predictions = 0002c.predict
only testing
average    since       example  example    current  current  current
loss       last        counter   weight      label  predict features
0.001778   0.001778          3      3.0     0.5498   0.5288      184
0.026911   0.052045          6      6.0     0.2681   0.6416      184
0.024174   0.020889         11     11.0     0.4315   0.5869      184
0.033938   0.043701         22     22.0     0.5519   0.4996      184
0.021159   0.008381         44     44.0     0.5514   0.5242      184
0.020368   0.019557         87     87.0     0.5140   0.4852      184
0.015119   0.009871        174    174.0     0.5596   0.4972      184
0.012454   0.009789        348    348.0     0.5475   0.4336      184
0.011079   0.009703        696    696.0     0.3421   0.7151      184
0.011197   0.011316       1392   1392.0     0.4996   0.4925      184
0.009159   0.007120       2784   2784.0     0.5090   0.4137      184
0.008413   0.007667       5568   5568.0     0.6413   0.5986      184
0.007835   0.007257      11135  11135.0     0.3869   0.5028      184
0.008269   0.008702      22269  22269.0     0.5063   0.4464      184
0.011104   0.013939      44537  44537.0     0.4905   0.4881      184

finished run
number of examples = 74746
weighted example sum = 6.952e+04
weighted label sum = 3.511e+04
average loss = 0.009452
best constant = 0.5051
best constant's loss = 0.25
total feature number = 13753264
