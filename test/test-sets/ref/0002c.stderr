using no cache
Reading from train-sets/0002.dat
num sources = 1
Num weight bits = 18
learning rate = 10
initial_t = 1
power_t = 0.5
predictions = 0002c.predict
only testing
average    since       example  example    current  current  current
loss       last        counter   weight      label  predict features
0.002292   0.002292          3      3.0     0.5498   0.5358      184
0.031932   0.061572          6      6.0     0.2681   0.6719      184
0.027998   0.023277         11     11.0     0.4315   0.6005      184
0.042498   0.056998         22     22.0     0.5519   0.5007      184
0.025631   0.008765         44     44.0     0.5514   0.5343      184
0.024115   0.022563         87     87.0     0.5140   0.5308      184
0.018563   0.013011        174    174.0     0.5596   0.4986      184
0.016115   0.013667        348    348.0     0.5475   0.4430      184
0.015137   0.014158        696    696.0     0.3421   0.7932      184
0.014835   0.014533       1392   1392.0     0.4996   0.5060      184
0.013021   0.011207       2784   2784.0     0.5090   0.3874      184
0.012235   0.011449       5568   5568.0     0.6413   0.7574      184
0.011139   0.010043      11135  11135.0     0.3869   0.4863      184
0.011152   0.011165      22269  22269.0     0.5063   0.4508      184
0.015868   0.020585      44537  44537.0     0.4905   0.5237      184

finished run
number of examples = 74746
weighted example sum = 6.952e+04
weighted label sum = 3.511e+04
average loss = 0.01427
best constant = 0.5051
best constant's loss = 0.25
total feature number = 13753264
