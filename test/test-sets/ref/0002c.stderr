only testing
Num weight bits = 18
learning rate = 10
initial_t = 1
power_t = 0.5
predictions = 0002c.predict
using no cache
Reading datafile = train-sets/0002.dat
num sources = 1
average    since         example     example  current  current  current
loss       last          counter      weight    label  predict features
0.003278   0.003278            3         3.0   0.5498   0.4854       15
0.024311   0.045343            6         6.0   0.2681   0.5754       15
0.025813   0.027616           11        11.0   0.4315   0.5104       15
0.039711   0.053610           22        22.0   0.5519   0.4650       15
0.029343   0.018975           44        44.0   0.5514   0.5169       15
0.026609   0.023811           87        87.0   0.5140   0.4809       15
0.023397   0.020186          174       174.0   0.5596   0.4550       15
0.018322   0.013246          348       348.0   0.5475   0.4075       15
0.015026   0.011730          696       696.0   0.3421   0.7545       15
0.013894   0.012762         1392      1392.0   0.4996   0.4691       15
0.011295   0.008697         2784      2784.0   0.5090   0.4428       15
0.009821   0.008347         5568      5568.0   0.6413   0.7065       15
0.008717   0.007612        11135     11135.0   0.3869   0.4381       15
0.008073   0.007430        22269     22269.0   0.5063   0.4481       15
0.011797   0.015520        44537     44537.0   0.4905   0.3865       15

finished run
number of examples per pass = 74746
passes used = 1
weighted example sum = 6.952e+04
weighted label sum = 3.511e+04
average loss = 0.01063
best constant = 0.5051
best constant's loss = 0.25
total feature number = 1119986
