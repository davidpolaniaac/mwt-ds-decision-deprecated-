only testing
Num weight bits = 18
learning rate = 10
initial_t = 1
power_t = 0.5
predictions = 0002c.predict
using no cache
Reading datafile = train-sets/0002.dat
num sources = 1
average    since         example     example  current  current  current
loss       last          counter      weight    label  predict features
0.000464   0.000464            1         1.0   0.5211   0.4996       15
0.002814   0.005164            2         2.0   0.5353   0.4634       15
0.007663   0.012511            4         4.0   0.5854   0.4407       15
0.028496   0.049329            8         8.0   0.5575   0.4417       15
0.032121   0.035746           16        16.0   0.5878   0.4856       15
0.033784   0.035448           32        32.0   0.6038   0.4587       15
0.024142   0.014499           64        64.0   0.5683   0.5709       15
0.023094   0.022045          128       128.0   0.5351   0.5345       15
0.019620   0.016147          256       256.0   0.5385   0.4893       15
0.015332   0.011044          512       512.0   0.5053   0.4533       15
0.014235   0.013139         1024      1024.0   0.5750   0.5082       15
0.012660   0.011085         2048      2048.0   0.5204   0.5024       15
0.010422   0.008184         4096      4096.0   0.5042   0.4605       15
0.009502   0.008583         8192      8192.0   0.4967   0.4662       15
0.008239   0.006975        16384     16384.0   0.5011   0.5380       15
0.009165   0.010091        32768     32768.0   0.3915   0.5794       15
0.011114   0.013062        65536     65536.0   0.5043   0.4496       15

finished run
number of examples per pass = 74746
passes used = 1
weighted example sum = 69521
weighted label sum = 35113.3
average loss = 0.0106413
best constant = 0.505067
best constant's loss = 0.249974
total feature number = 1119986
