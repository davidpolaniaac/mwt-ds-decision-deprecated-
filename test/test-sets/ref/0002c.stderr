using no cache
Reading from train-sets/0002.dat
num sources = 1
Num weight bits = 18
learning rate = 10
initial_t = 1
power_t = 0.5
predictions = 0002c.predict
only testing
average    since       example  example    current  current  current
loss       last        counter   weight      label  predict features
0.002451   0.002451          3      3.0     0.5498   0.5290      184
0.026226   0.050001          6      6.0     0.2681   0.6256      184
0.021953   0.016825         11     11.0     0.4315   0.5740      184
0.038339   0.054725         22     22.0     0.5519   0.5148      184
0.022545   0.006752         44     44.0     0.5514   0.5516      184
0.021625   0.020684         87     87.0     0.5140   0.5625      184
0.017691   0.013757        174    174.0     0.5596   0.5038      184
0.015168   0.012645        348    348.0     0.5475   0.5091      184
0.014766   0.014364        696    696.0     0.3421   0.8052      184
0.014233   0.013700       1392   1392.0     0.4996   0.5151      184
0.013353   0.012474       2784   2784.0     0.5090   0.4002      184
0.013103   0.012853       5568   5568.0     0.6413   0.8970      184
0.011524   0.009944      11135  11135.0     0.3869   0.4721      184
0.012472   0.013420      22269  22269.0     0.5063   0.4566      184
0.018489   0.024505      44537  44537.0     0.4905   0.5291      184

finished run
number of examples = 74746
weighted example sum = 6.952e+04
weighted label sum = 3.511e+04
average loss = 0.01683
best constant = 0.5051
best constant's loss = 0.25
total feature number = 13753264
